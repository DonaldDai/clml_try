{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a50add72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClearML Task: created new task id=a070a28209d646299bb99168f5370ae5\n",
      "ClearML results page: http://167.86.107.213:8080/projects/0963014461cf4fe0bc7b739b2dffb0ef/experiments/a070a28209d646299bb99168f5370ae5/output/log\n",
      "2024-06-30 21:53:06,094 - clearml.Task - INFO - Storing jupyter notebook directly as code\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not fetch function declared in __main__: <module '__main__'> is a built-in module\n",
      "Could not fetch function imports: <module '__main__'> is a built-in module\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClearML pipeline page: http://167.86.107.213:8080/pipelines/0963014461cf4fe0bc7b739b2dffb0ef/experiments/a070a28209d646299bb99168f5370ae5\n",
      "Launching step [step]\n",
      "ClearML results page: http://167.86.107.213:8080/projects/0963014461cf4fe0bc7b739b2dffb0ef/experiments/c7c493b655a2493194121f2f2bb164d6/output/log\n"
     ]
    }
   ],
   "source": [
    "from clearml import PipelineDecorator\n",
    "\n",
    "@PipelineDecorator.component(cache=True, execution_queue=\"default\")\n",
    "def step(size: int):\n",
    "    import numpy as np\n",
    "    return np.random.random(size=size)\n",
    "\n",
    "@PipelineDecorator.pipeline(\n",
    "    name='ingest',\n",
    "    project='data processing',\n",
    "    version='0.1'\n",
    ")\n",
    "def pipeline_logic(do_stuff: bool):\n",
    "    if do_stuff:\n",
    "        return step(size=42)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # run the pipeline on the current machine, for local debugging\n",
    "    # for scale-out, comment-out the following line (Make sure a\n",
    "    # 'services' queue is available and serviced by a ClearML agent\n",
    "    # running either in services mode or through K8S/Autoscaler)\n",
    "    PipelineDecorator.run_locally()\n",
    "\n",
    "    pipeline_logic(do_stuff=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea189b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClearML Task: created new task id=5792ff1dfa8341158b1bed92fa26326a\n",
      "ClearML results page: http://167.86.107.213:8080/projects/e9945973084a40eda1f86165f281cf19/experiments/5792ff1dfa8341158b1bed92fa26326a/output/log\n",
      "2024-07-01 02:25:38,317 - clearml.Task - INFO - Storing jupyter notebook directly as code\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not fetch function declared in __main__: <module '__main__'> is a built-in module\n",
      "Could not fetch function imports: <module '__main__'> is a built-in module\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClearML pipeline page: http://167.86.107.213:8080/pipelines/e9945973084a40eda1f86165f281cf19/experiments/5792ff1dfa8341158b1bed92fa26326a\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Switching to remote execution, output log page http://167.86.107.213:8080/projects/e9945973084a40eda1f86165f281cf19/experiments/5792ff1dfa8341158b1bed92fa26326a/output/log\n"
     ]
    }
   ],
   "source": [
    "from clearml import PipelineController\n",
    "\n",
    "pipe = PipelineController(\n",
    "  name=\"try\", project=\"eval\"\n",
    ")\n",
    "\n",
    "pipe.add_parameter(\n",
    "    name='name',\n",
    "    description='aa', \n",
    "    default='1'\n",
    ")\n",
    "def pre_execute_callback_example(a_pipeline, a_node, current_param_override):\n",
    "    # type (PipelineController, PipelineController.Node, dict) -> bool\n",
    "    print(\n",
    "        \"Cloning Task id={} with parameters: {}\".format(\n",
    "            a_node.base_task_id, current_param_override\n",
    "        )\n",
    "    )\n",
    "    # if we want to skip this node (and subtree of this node) we return False\n",
    "    # return True to continue DAG execution\n",
    "    return True\n",
    "\n",
    "\n",
    "def post_execute_callback_example(a_pipeline, a_node):\n",
    "    # type (PipelineController, PipelineController.Node) -> None\n",
    "    print(\"Completed Task id={}\".format(a_node.executed))\n",
    "    # if we need the actual executed Task: Task.get_task(task_id=a_node.executed)\n",
    "    return\n",
    "\n",
    "def step_one():\n",
    "    return 4, 5\n",
    "pipe.set_default_execution_queue('gpu')\n",
    "pipe.add_function_step(\n",
    "     name='step_one',\n",
    "     function=step_one,\n",
    "     function_return=['aa', 'bb'],\n",
    "     cache_executed_step=True,\n",
    ")\n",
    "pipe.add_step(\n",
    "   name='run_task',\n",
    "   parents=['step_one', ],\n",
    "   base_task_id='5bea612ec5254abaa1ab9894a7af2fc8',\n",
    "   parameter_override={\n",
    "     'Args/aa': '9',\n",
    "     'Args/bb': '10',\n",
    "   },\n",
    "#    pre_execute_callback=pre_execute_callback_example,\n",
    "#    post_execute_callback=post_execute_callback_example,\n",
    ")\n",
    "pipe.start('gpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de93c62a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
